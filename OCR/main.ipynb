{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.filters import threshold_local\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('D:\\\\IA\\\\OCR\\\\OCR_result\\\\11.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orientation_correction(img, save_image = False): \n",
    "    # GrayScale Conversion for the Canny Algorithm  \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    img_edges = cv2.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "    # Using Houghlines to detect lines\n",
    "    lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=100, maxLineGap=5)\n",
    "    \n",
    "    # Finding angle of lines in polar coordinates\n",
    "    angles = []\n",
    "    for x1, y1, x2, y2 in lines[0]:\n",
    "        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "        angles.append(angle)\n",
    "    \n",
    "    # Getting the median angle\n",
    "    median_angle = np.median(angles)\n",
    "    \n",
    "    # Rotating the image with this median angle\n",
    "    img_rotated = ndimage.rotate(img, median_angle)\n",
    "    \n",
    "    return img_rotated\n",
    "\n",
    "\n",
    "def bw_scanner(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    T = threshold_local(gray, 21, offset = 5, method = \"gaussian\")\n",
    "    return (gray > T).astype(\"uint8\") * 255\n",
    "\n",
    "\n",
    "def noise_removal(image):\n",
    "    import numpy as np\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return (image)\n",
    "##\n",
    "grayImage2 = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2RGB)\n",
    "finalImg = cv2.cvtColor(bw_scanner(grayImage2), cv2.COLOR_GRAY2RGB)\n",
    "cv2.imwrite(\"D:\\\\IA\\\\OCR\\\\OCR_result\\\\output.jpg\",finalImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CFG = \"D:\\\\IA\\\\OCR\\\\Tensorflow\\\\workspace\\\\models\\\\model2\\\\pipeline.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',\"model2\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_config = configs['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-22')).expect_partial()\n",
    "\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = \"D:\\\\IA\\\\OCR\\\\Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "cBDbIhNapfDI"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "Lx3crOhOzITB"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"D:\\\\IA\\\\OCR\\\\OCR_result\\\\output.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Tpzn1SMry1yK",
    "outputId": "c392a2c5-10fe-4fc4-9998-a1d4c7db2bd3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=10,\n",
    "            min_score_thresh=.3,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "cv2.imwrite('D:\\\\IA\\\\OCR\\\\OCR_result\\\\result2.jpg',image_np_with_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from cv2 import resizeWindow\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "#ocr_model = PaddleOCR(lang='chinese_cht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(benchmark=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\USER/.paddleocr/2.2.0.2\\\\ocr\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, det=True, det_algorithm='DB', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\USER/.paddleocr/2.2.0.2\\\\ocr\\\\det\\\\en\\\\en_ppocr_mobile_v2.0_det_infer', det_sast_nms_thresh=0.2, det_sast_polygon=False, det_sast_score_thresh=0.5, drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_polygon=True, e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, gpu_mem=500, help='==SUPPRESS==', image_dir=None, ir_optim=True, label_list=['0', '180'], lang='chinese_cht', layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', max_batch_size=10, max_text_length=25, min_subgraph_size=10, output='./output/table', precision='fp32', process_id=0, rec=True, rec_algorithm='CRNN', rec_batch_num=6, rec_char_dict_path='D:\\\\Anaconda\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\chinese_cht_dict.txt', rec_char_type='ch', rec_image_shape='3, 32, 320', rec_model_dir='C:\\\\Users\\\\USER/.paddleocr/2.2.0.2\\\\ocr\\\\rec\\\\chinese_cht\\\\chinese_cht_mobile_v2.0_rec_infer', save_log_path='./log_output/', show_log=True, table_char_dict_path=None, table_char_type='en', table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=True, use_mp=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=True)\n"
     ]
    }
   ],
   "source": [
    "ocr_model = PaddleOCR(use_angle_cls=True, lang=\"chinese_cht\",use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold = 0.3\n",
    "image = image_np_with_detections\n",
    "width = image.shape[1]\n",
    "height = image.shape[0]\n",
    "scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "boxes = detections['detection_boxes'][:len(scores)]\n",
    "classes = detections['detection_classes'][:len(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 2, elapse : 0.019008874893188477\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 2, elapse : 0.011067867279052734\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 2, elapse : 0.016076326370239258\n",
      "萬寧\n",
      "mGnnings\n",
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 2, elapse : 0.015949010848999023\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 2, elapse : 0.010378360748291016\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 2, elapse : 0.01528477668762207\n",
      "162.90\n",
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 1, elapse : 0.00897526741027832\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 1, elapse : 0.00948476791381836\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 1, elapse : 0.009318828582763672\n",
      "現金\n",
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 1, elapse : 0.013427734375\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 1, elapse : 0.00895833969116211\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 1, elapse : 0.013962507247924805\n",
      "03-09-2018 19:18339\n",
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 2, elapse : 0.01984858512878418\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 2, elapse : 0.009974241256713867\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 2, elapse : 0.0235135555267334\n",
      "stIme\n",
      "[2021/08/28 03:18:49] root DEBUG: dt_boxes num : 1, elapse : 0.011483907699584961\n",
      "[2021/08/28 03:18:49] root DEBUG: cls num  : 1, elapse : 0.00994563102722168\n",
      "[2021/08/28 03:18:49] root DEBUG: rec_res num  : 1, elapse : 0.01296544075012207\n",
      "下:52807216\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for idx, box in enumerate(boxes):\n",
    "    roi = box*[height, width, height, width]\n",
    "    region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
    "    ocr_result = ocr_model.ocr(region)\n",
    "    for result in ocr_result:\n",
    "        print(result[1][0])\n",
    "        temp.append(result[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['萬寧',\n",
       " 'mGnnings',\n",
       " '162.90',\n",
       " '現金',\n",
       " '03-09-2018 19:18339',\n",
       " 'stIme',\n",
       " '下:52807216']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result2\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#f = open('D:\\\\IA\\\\OCR\\\\OCR_result', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = ['Brand_name', 'Total', 'Payment method', 'Data time',\"recipt id\"]\n",
    "\n",
    "with open('Paddle_OCR_result.csv', 'w', encoding='utf-8-sig', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# csv header\n",
    "first_row = ['name', 'area', 'country_code2', 'country_code3']\n",
    "\n",
    "# csv data\n",
    "rows = [\n",
    "    {'name': 'Albania',\n",
    "    'area': 28748,\n",
    "    'country_code2': 'AL',\n",
    "    'country_code3': 'ALB'},\n",
    "    {'name': 'Algeria',\n",
    "    'area': 2381741,\n",
    "    'country_code2': 'DZ',\n",
    "    'country_code3': 'DZA'},\n",
    "    {'name': 'American Samoa',\n",
    "    'area': 199,\n",
    "    'country_code2': 'AS',\n",
    "    'country_code3': 'ASM'}\n",
    "]\n",
    "\n",
    "with open('countries.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5c62bd78bb557adc775a776e42d8ffd77858fdcc0e2ee124184787f5ac4372d7"
  },
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
